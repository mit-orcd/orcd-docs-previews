{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MIT Office of Research Computing and Data Hands On Help Pages","text":"<p>The MIT Office or Research Computing and Data (ORCD) provides access and support for the compute and data needs of a wide range of research activities. These pages provide  help material for hands-on working with ORCD supported services. </p> <p>Help working with ORCD services is also available through email to orcd-help@mit.edu, please  feel free to contact us with questions and suggestions.</p>"},{"location":"data-security/","title":"Data Security and Privacy","text":""},{"location":"data-security/#what-data-can-be-stored","title":"What data can be stored?","text":"<p>All ORCD current systems are only suitable for storing data with low-level security requirements. This means that they are not to be used to store sensitive data, such as personal information, financial information, or intellectual property. Additionally, they are not to be used to store data that is subject to use agreements that require security controls or audit tracking.</p> <p>The following data categories are appropriate for storing and analyzing on current ORCD systems:</p> <p>Open public data Low-sensitivity private research data Low-sensitivity research data are items such as drafts of papers and analyses derived from public data.</p> <p>The following data types are suitable for ORCD systems:</p> <ul> <li>Anything in the low-risk category described at the MIT IS&amp;T information security pages</li> <li>Drafts of unpublished research papers and results that are based on low-risk data</li> </ul> <p>Anything else in the medium-risk or higher risk levels of the MIT IS&amp;T information security pages should not be stored or analyzed on current ORCD systems.</p> <p>If you have any questions about whether your data is appropriate for storing on ORCD systems please feel free to reach out to us at orcd-help@mit.edu. </p>"},{"location":"data-security/#where-can-more-sensitive-data-be-processed-and-stored","title":"Where can more sensitive data be processed and stored?","text":"<p>The ORCD team is currently developing a system for more sensitive data. If you have sensitive data and would like to learn about our plans please feel free to get in touch at orcd-help@mit.edu.</p>"},{"location":"orcd-systems/","title":"ORCD Systems","text":"<p>ORCD operates and provides support and training for a number of cluster computer systems available to all researchers. These systems all run with a Slurm scheduler and have a web portal for interactive computing. These are Engaging, SuperCloud, and Satori.</p>","tags":["Engaging","Satori","SuperCloud"]},{"location":"orcd-systems/#engaging-cluster","title":"Engaging Cluster","text":"<p>The engaging cluster is a mixed CPU and GPU computng cluster that is openly available to all  research projects at MIT. It has around 80,000 x86 CPU cores and 300  GPU cards ranging from K80 generation to recent Voltas. Hardware access is through the Slurm  resource scheduler that supports batch and interactive workloads and allows dedicated reservations. The cluster has a large shared file system for working datasets. Additional compute and storage  resources can be purchased by PIs. A wide range of standard software is available and the Docker  compatible Singularity container tool is supported. User-level tools like Anaconda for Python,  R libraries and Julia packages are all supported. A range of PI group maintained custom software  stacks are also available through the widely adopted environment modules toolkit. A standard,  open-source, web-based portal supporting Jupyter notebooks, R studio, Mathematica and X graphics  is available at https://engaging-ood.mit.edu. Further information and support is available from orcd-help-engaging@mit.edu.</p>","tags":["Engaging","Satori","SuperCloud"]},{"location":"orcd-systems/#how-to-get-an-account-on-engaging","title":"How to Get an Account on Engaging","text":"<p>Accounts on the engaging cluster are connected to your main MIT institutional kerberos id.  Connecting to the cluster for the first time through its web portal automatically activates an account with basic access to resources. See this page for instructions on how to log in.</p>","tags":["Engaging","Satori","SuperCloud"]},{"location":"orcd-systems/#engaging-quick-links","title":"Engaging Quick Links","text":"<ul> <li>Documentation: https://engaging-web.mit.edu/eofe-wiki/</li> <li>OnDemand web portal: https://engaging-ood.mit.edu</li> <li>Help: Send email to orcd-help-engaging@mit.edu</li> </ul>","tags":["Engaging","Satori","SuperCloud"]},{"location":"orcd-systems/#satori","title":"Satori","text":"<p>Satori is an IBM Power 9 large memory node system. It is open to everyone on campus and has  optimized software stacks for machine learning and for image stack post-processing for  MIT.nano Cryo-EM facilities. The system has 256 NVidia Volta GPU cards attached in groups of  four to 1TB memory nodes and a total of 2560 Power 9 CPU cores. Hardware access is through the  Slurm resource scheduler that supports batch and interactive workload and allows dedicated  reservations. A wide range of standard software is available and the Docker compatible  Singularity container tool is supported. A standard web based portal  https://satori-portal.mit.edu with Jupyter notebook support is available. Additional compute  and storage resources can be purchased by PIs and integrated into the system. Further  information and support is available at orcd-help-satori@mit.edu.</p>","tags":["Engaging","Satori","SuperCloud"]},{"location":"orcd-systems/#how-to-get-an-account-on-satori","title":"How to Get an Account on Satori","text":"<p>You can get an account by logging into https://satori-portal.mit.edu with your MIT credentials.  See this page for instructions: https://mit-satori.github.io/satori-basics.html#how-can-i-get-an-account.</p>","tags":["Engaging","Satori","SuperCloud"]},{"location":"orcd-systems/#satori-quick-links","title":"Satori Quick Links","text":"<ul> <li>Documentation: (https://mit-satori.github.io/</li> <li>OnDemand web portal: https://satori-portal.mit.edu</li> <li>Help: Send email to orcd-help-satori@mit.edu</li> <li>Slack: https://mit-satori.slack.com/</li> </ul>","tags":["Engaging","Satori","SuperCloud"]},{"location":"orcd-systems/#supercloud","title":"SuperCloud","text":"<p>The SuperCloud system is a collaboration with MIT Lincoln Laboratory on a shared facility that  is optimized for streamlining open research collaborations with Lincoln Laboratory. The facility  is open to everyone on campus. The latest SuperCloud system has more than 16,000 x86 CPU cores  and more than 850 NVidia Volta GPUs in total. Hardware access is through the Slurm resource  scheduler that supports batch and interactive workload and allows dedicated reservations. A wide  range of standard software is available and the Docker compatible Singularity container tool is  supported. A custom, web-based portal supporting Jupyter notebooks is available at https://txe1-portal.mit.edu/. Further information and support is available at  supercloud@mit.edu.</p>","tags":["Engaging","Satori","SuperCloud"]},{"location":"orcd-systems/#how-to-get-an-account-on-supercloud","title":"How to Get an Account on SuperCloud","text":"<p>To request a SuperCloud account follow the instructions on this page:  https://supercloud.mit.edu/requesting-account.</p>","tags":["Engaging","Satori","SuperCloud"]},{"location":"orcd-systems/#supercloud-quick-links","title":"SuperCloud Quick Links","text":"<ul> <li>Documentation: https://supercloud.mit.edu/</li> <li>Online Course: https://learn.llx.edly.io/course/practical-hpc/</li> <li>Web portal: https://txe1-portal.mit.edu/</li> <li>Help: Send email to supercloud@mit.edu</li> </ul>","tags":["Engaging","Satori","SuperCloud"]},{"location":"orcd-systems/#openmind","title":"OpenMind","text":"<p>The OpenMind system is a collaboration with Department of Brain and Cognitive Sciences (BCS) and McGovern Institute. OpenMind is mainly a GPU computing cluster optimized for artificial intelligence (AI) research and data science. Totally there are around 70 compute nodes, 3500 CPU cores, 48 TB of RAM, and 340 GPUs, including 142 A100-80GB GPUs. It also provides around 2 PB of flash storage supporting fast read/write data speed. Hardware access is through the Slurm resource scheduler that supports batch and interactive workload and allows dedicated reservations. A wide range of standard software is available and Docker compatible Apptainer/Singularity container tool is supported. User-level tools like Anaconda for Python, R libraries and Julia packages are all supported. Further information and support is available at orcd-help-openmind@mit.edu.</p>","tags":["Engaging","Satori","SuperCloud"]},{"location":"orcd-systems/#how-to-get-an-account-on-openmind","title":"How to Get an Account on OpenMind","text":"<p>Accounts will be available for MIT users in 2024.</p>","tags":["Engaging","Satori","SuperCloud"]},{"location":"orcd-systems/#openmind-quick-links","title":"OpenMind Quick Links","text":"<ul> <li>Documentation: https://github.mit.edu/MGHPCC/OpenMind/wiki</li> <li>Home Page and Online Course: https://openmind.mit.edu/</li> <li>Help: Send email to orcd-help-openmind@mit.edu</li> <li>Slack: https://openmind-46.slack.com</li> </ul>","tags":["Engaging","Satori","SuperCloud"]},{"location":"tags/","title":"Tags","text":"<p>Following is a list of relevant tags:</p>"},{"location":"tags/#engaging","title":"Engaging","text":"<ul> <li>ORCD Systems</li> <li>Example of a build of the VASP software.</li> <li>GROMACS</li> <li>MuJoCo</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#gpu","title":"GPU","text":"<ul> <li>Example of a build of the VASP software.</li> <li>GROMACS</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#gromacs","title":"GROMACS","text":"<ul> <li>GROMACS</li> </ul>"},{"location":"tags/#h100","title":"H100","text":"<ul> <li>Getting started on 8-way H100 nodes on Satori</li> </ul>"},{"location":"tags/#howto-recipes","title":"Howto Recipes","text":"<ul> <li>Example of a build of the VASP software.</li> <li>GROMACS</li> <li>Getting started on 8-way H100 nodes on Satori</li> <li>MPI for Python</li> <li>MuJoCo</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#mpi","title":"MPI","text":"<ul> <li>Example of a build of the VASP software.</li> <li>GROMACS</li> <li>MPI for Python</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#mujoco","title":"MuJoCo","text":"<ul> <li>MuJoCo</li> </ul>"},{"location":"tags/#openmind","title":"OpenMind","text":"<ul> <li>MPI for Python</li> </ul>"},{"location":"tags/#python","title":"Python","text":"<ul> <li>MPI for Python</li> </ul>"},{"location":"tags/#rocky-linux","title":"Rocky Linux","text":"<ul> <li>Example of a build of the VASP software.</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#satori","title":"Satori","text":"<ul> <li>ORCD Systems</li> <li>Getting started on 8-way H100 nodes on Satori</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#supercloud","title":"SuperCloud","text":"<ul> <li>ORCD Systems</li> <li>GROMACS</li> <li>MuJoCo</li> </ul>"},{"location":"tags/#vasp","title":"VASP","text":"<ul> <li>Example of a build of the VASP software.</li> </ul>"},{"location":"tags/#cuda","title":"cuda","text":"<ul> <li>Example of a build of the VASP software.</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#cuda-aware-mpi","title":"cuda aware mpi","text":"<ul> <li>Example of a build of the VASP software.</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#nvhpc","title":"nvhpc","text":"<ul> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"filesystems-file-transfer/filesystems/","title":"General Use Filesystems","text":"<p>Large HPC systems often have different filesystems for different purposes. ORCD systems are no different, and each have their own approach. This page documents these.</p>"},{"location":"filesystems-file-transfer/filesystems/#supercloud","title":"SuperCloud","text":"<p>SuperCloud uses Lustre for all central/shared storage (accessible to all nodes in the system). This storage is not backed up. See the SuperCloud Best Practices and Performance Tips page for best practices using the Lustre filesystem. Quotas or limits are set on the storage as guardrails. Additional storage may be granted on a case by case basis. Local disk spaces will be faster than the Lustre shared filesystem, but all are temporary and can only be accessed on the node where they are created.</p> Storage Type Path Access Backed up Limits Home Directory  Lustre <code>/home/gridsan/&lt;username&gt;</code> User only Not backed up See User Profile Page Group Directories  Lustre <code>/home/gridsan/groups/&lt;groupname&gt;</code> Files shared within a group Not backed up See User Profile Page Job-specific Temporary Storage  Local Disk Access using the <code>$TMPDIR</code> environment variable User or Group Not backed up   Temporary directory created at the start of a job and cleaned up at the end of the job NA Local Disk Space Create the directory <code>/state/partition1/user/$USER</code> as needed User or Group Not backed up  Cleaned up monthly during downtimes NA"},{"location":"filesystems-file-transfer/filesystems/#engaging","title":"Engaging","text":"<p>Users each get a small home directory that is backed up and meant for important files. Larger scratch space is not backed up. Additional storage can be purchased. The Lustre scratch space will be faster than NFS for the majority of workloads, however having large numbers of small files will make it slower than NFS and can slow down the filesystem overall, so it is important to follow the Lustre Best Practices. See the Engaging Documentation Page on Storage for more information.</p> Storage Type Path Quota Backed up Purpose/Notes Home Directory  NFS <code>/home/&lt;username&gt;</code> 100 GB Backed up Use for important files Lustre <code>/nobackup1/&lt;username&gt;</code> 1 TB Not backed up Scratch space  Faster than NFS NFS <code>/pool001/&lt;username&gt;</code> 1 TB Not backed up Scratch space"},{"location":"filesystems-file-transfer/filesystems/#satori","title":"Satori","text":"Storage Type Path Quota Backed up Purpose/Notes Home Directory <code>/home/&lt;username&gt;</code> 25GB Backed up Use for important files. Quota increase request to 100GB. GPFS <code>/nobackup/users/&lt;username&gt;</code> 500GB Not backed up Scratch space. Quota increase request to 2TB."},{"location":"filesystems-file-transfer/filesystems/#openmind","title":"OpenMind","text":"<p>OpenMind provides a number of different storage options. See the OpenMind Documentation page on Storage for more information, best practices, and recommendations.</p> Storage Type Path Quota Backed up Purpose/Notes Home Directory <code>/home/&lt;username&gt;</code> 20 GB Backed up Use for very important files. Physically located on Vast. Weka <code>/om/user/&lt;username&gt;</code> (individual users) and <code>/om/group/&lt;groupname&gt;</code> (groups) Per group Backed up Fast internal storage Weka Scratch <code>/om/scratch/&lt;week-day&gt;</code> N/A Not backed up  purged 3 weeks after creation Scratch space Vast <code>/om2/user/&lt;username&gt;</code> (individual users) and <code>/om2/group/&lt;groupname&gt;</code> (groups) Per group Backed up Fast internal storage Vast Scratch <code>/om2/scratch/&lt;week-day&gt;</code> N/A Not backed up  purged 2 weeks after creation Scratch space Lustre Scratch <code>/nobackup/scratch/&lt;week-day&gt;</code> N/A Not backed up  purged 3 weeks after creation Scratch space   See Lustre Best Practices page NFS <code>/om3</code>, <code>/om4</code>, <code>/om5</code> Per group Backed up Slow internal long-term storage NESE <code>/nese</code> Per group Backed up Slow internal long-term storage"},{"location":"filesystems-file-transfer/project-filesystems/","title":"Project Specific Filesystems","text":""},{"location":"filesystems-file-transfer/project-filesystems/#purchasing-storage","title":"Purchasing Storage","text":"<p>Additional project and lab storage can be purchased on ORCD shared clusters by individual PI groups. This storage is mounted on the cluster and access to the storage is managed  by the group through MIT Web Moira, https://groups.mit.edu/webmoira/ (see below for details).</p> <p>Current pricing for storage is</p> Storage Type Pricing Duration Backup NESE encrypted at rest   disk. $2.50/month  50TB minimum,    10TB increments. 12 month  minimum. No automated backup. <p>The NESE encrypted at rest disk uses a large centrally managed storage cloud at the MGHPCC facility. Any shared ORCD cluster at the MGHPCC can access this storage. Data on NESE disk is transparently encrypted at rest.</p> <p>To purchase storage please send an email to orcd-help@mit.edu.</p>"},{"location":"filesystems-file-transfer/project-filesystems/#managing-access-using-mit-web-moira","title":"Managing access using MIT Web Moira","text":"<p>Individual group storage is configured so that access is limited to a set of accounts belonging to a web moira list that is defined for the group store. The owner and administrators of group storage can manage access themselves, by modifying the membership of an associated moira list under https://groups.mit.edu/webmoira/list/. The name of the list corresponds to the UNIX group name associated with the ORCD shared  cluster storage.</p>"},{"location":"filesystems-file-transfer/project-filesystems/#moira-web-interface-example","title":"Moira Web Interface Example","text":"<p>The figure below shows a screenshot of the web moira management page at https://groups.mit.edu/webmoira/list/cnh_research_computing for a hypothetical storage group named <code>cnh_research_computing</code>. The interface provides a  self-service mechanism for controlling access to any storage belonging to this group. MIT account ids can be added and  removed as needed from this list by the storage access administrators.</p> <p></p>"},{"location":"images/","title":"Index","text":""},{"location":"images/#directory-of-static-images","title":"Directory of static images","text":""},{"location":"recipes/basic_vasp_gcc_example/","title":"Example of a build of the VASP software.","text":"","tags":["Engaging","Howto Recipes","MPI","cuda","cuda aware mpi","GPU","VASP","Rocky Linux"]},{"location":"recipes/basic_vasp_gcc_example/#about-vasp","title":"About VASP","text":"<p>VASP is a first principles simulation tool for electronic structure and quantum mechanical molelcular dynamics computations. The name VASP is an acronym of Vienna Ab-initio Simulation Package. The VASP software is used in quantum chemistry to simulate the properties and structure of atomic scale materials. VASP can compute detailed atomic structure of molecules, finding terms such as bond lengths and vibration frequencies.</p>","tags":["Engaging","Howto Recipes","MPI","cuda","cuda aware mpi","GPU","VASP","Rocky Linux"]},{"location":"recipes/basic_vasp_gcc_example/#building-vasp-software","title":"Building VASP software","text":"<p>VASP is distributed as Fortran source code that must be compiled by end-users to create an executable program. This recipe describes how to compile VASP using the GNU compiler stack. The recipe shows commands for a Rocky Linux system.</p> <p>Prerequisites</p> <ul> <li>To use VASP a research group must obtain a license from the VASP team as described here here.</li> <li>This example assumes you have access to a Slurm partition and are working with a Rocky Linux environment.</li> </ul>","tags":["Engaging","Howto Recipes","MPI","cuda","cuda aware mpi","GPU","VASP","Rocky Linux"]},{"location":"recipes/basic_vasp_gcc_example/#1-extract-vasp-source-code-files","title":"1. Extract VASP source code files","text":"<p>Once a licensed copy of VASP has been obtained the source code files must be extracted from the tar file that can be downloaded by license holders from the VASP portal site. The command</p> <pre><code>tar -xzvf vasp.6.4.2.tgz\n</code></pre> <p>will extract the source files and their directory tree. This command should be executed in a sub-directory where you will store the compiled VASP programs. </p> <p>Once the code has been extracted, switch to use the VASP directory for the remaining steps</p> <pre><code>cd vasp.6.4.2\n</code></pre> Tip <p>For different versions of VASP, the download file name and directory name will be different. In that case, remember to adjust the example commands above accordingly.</p>","tags":["Engaging","Howto Recipes","MPI","cuda","cuda aware mpi","GPU","VASP","Rocky Linux"]},{"location":"recipes/basic_vasp_gcc_example/#2-configure-the-compiler-options-file","title":"2. Configure the compiler options file","text":"<p>The VASP software is distributed with multiple example compiler options files.  These are in the sub-directory <code>arch/</code>.  For this example we will use the GNU compiler options file <code>makefile.include.gnu_omp</code>.  To activate the chosen options, copy the options file into the top-level VASP directory.</p> <pre><code>cp arch/makefile.include.gnu_omp makefile.include\n</code></pre>","tags":["Engaging","Howto Recipes","MPI","cuda","cuda aware mpi","GPU","VASP","Rocky Linux"]},{"location":"recipes/basic_vasp_gcc_example/#3-activate-the-relevant-modules","title":"3. Activate the relevant modules","text":"<p>To build the vasp program from the licensed source code several tools and libraries are needed.  The modules below add the needed software.  The <code>gcc</code> and <code>openmpi</code> modules provide compilers (gcc) and computational tools (openmpi)  needed for parallel computing with VASP.  The <code>lapack</code>, <code>scalapack</code>, <code>fftw</code> and <code>openblas</code> toos are numerical libraries that VASP uses.</p> <pre><code>module load gcc/12.2.0-x86_64\nmodule load openmpi/4.1.4-pmi-cuda-ucx-x86_64\nmodule load netlib-lapack/3.10.1-x86_64\nmodule load netlib-scalapack/2.2.0-x86_64\nmodule load fftw/3.3.10-x86_64\nmodule load openblas/0.3.21-x86_64\n</code></pre>","tags":["Engaging","Howto Recipes","MPI","cuda","cuda aware mpi","GPU","VASP","Rocky Linux"]},{"location":"recipes/basic_vasp_gcc_example/#4-set-environment-variables-that-are-needed-for-compilation","title":"4. Set environment variables that are needed for compilation","text":"<p>The compilation scripts that come with VASP include variables that must be set to the clusters local values. Here we set environment variables to hold those settings.</p> <pre><code>SCALAPACK_ROOT=`module -t show  netlib-scalapack 2&gt;&amp;1 | grep CMAKE_PREFIX_PATH | awk -F, '{print $2}'  | awk -F\\\" '{print $2}'`\nFFTW_ROOT=`pkgconf --variable=prefix fftw3`\nOPENBLAS_ROOT=$(dirname `pkgconf --variable=libdir openblas`)\n</code></pre>","tags":["Engaging","Howto Recipes","MPI","cuda","cuda aware mpi","GPU","VASP","Rocky Linux"]},{"location":"recipes/basic_vasp_gcc_example/#5-compile-the-vasp-code","title":"5. Compile the VASP code","text":"<p>To compile the VASP code use the <code>make</code> program, passing it the environment variable settings as shown. The settings shown will also build the Fortran 90 modules that VASP includes. Typically th</p> <pre><code>make -j OPENBLAS_ROOT=$OPENBLAS_ROOT FFTW_ROOT=$FFTW_ROOT SCALAPACK_ROOT=$SCALAPACK_ROOT MODS=1 DEPS=1\n</code></pre>","tags":["Engaging","Howto Recipes","MPI","cuda","cuda aware mpi","GPU","VASP","Rocky Linux"]},{"location":"recipes/basic_vasp_gcc_example/#6-check-the-vasp-executables","title":"6. Check the VASP executables","text":"<p>The above commands should generate VASP executable programs <code>bin/vasp_std</code>, <code>bin/vasp_gam</code> and <code>bin/vasp_ncl</code>. To test that these programs can execute the following commands can be used.</p> <pre><code>export LD_LIBRARY_PATH=${OPENBLAS_ROOT}/lib:${FFTW_ROOT}/lib:${SCALAPACK_ROOT}/lib:${LD_LIBRARY_PATH}\nbin/vasp_std\n</code></pre> <p>if the code has compiled sucesfully the follow output should be generated. This output shows that the  VASP program can be run. The output shows an error because no input files have been configured.</p> <pre><code> -----------------------------------------------------------------------------\n|                                                                             |\n|     EEEEEEE  RRRRRR   RRRRRR   OOOOOOO  RRRRRR      ###     ###     ###     |\n|     E        R     R  R     R  O     O  R     R     ###     ###     ###     |\n|     E        R     R  R     R  O     O  R     R     ###     ###     ###     |\n|     EEEEE    RRRRRR   RRRRRR   O     O  RRRRRR       #       #       #      |\n|     E        R   R    R   R    O     O  R   R                               |\n|     E        R    R   R    R   O     O  R    R      ###     ###     ###     |\n|     EEEEEEE  R     R  R     R  OOOOOOO  R     R     ###     ###     ###     |\n|                                                                             |\n|     No INCAR found, STOPPING                                                |\n|                                                                             |\n|       ----&gt;  I REFUSE TO CONTINUE WITH THIS SICK JOB ... BYE!!! &lt;----       |\n|                                                                             |\n -----------------------------------------------------------------------------\n\n -----------------------------------------------------------------------------\n|                                                                             |\n|     EEEEEEE  RRRRRR   RRRRRR   OOOOOOO  RRRRRR      ###     ###     ###     |\n|     E        R     R  R     R  O     O  R     R     ###     ###     ###     |\n|     E        R     R  R     R  O     O  R     R     ###     ###     ###     |\n|     EEEEE    RRRRRR   RRRRRR   O     O  RRRRRR       #       #       #      |\n|     E        R   R    R   R    O     O  R   R                               |\n|     E        R    R   R    R   O     O  R    R      ###     ###     ###     |\n|     EEEEEEE  R     R  R     R  OOOOOOO  R     R     ###     ###     ###     |\n|                                                                             |\n|     No INCAR found, STOPPING                                                |\n|                                                                             |\n|       ----&gt;  I REFUSE TO CONTINUE WITH THIS SICK JOB ... BYE!!! &lt;----       |\n|                                                                             |\n -----------------------------------------------------------------------------\n\nSTOP 1\n</code></pre>","tags":["Engaging","Howto Recipes","MPI","cuda","cuda aware mpi","GPU","VASP","Rocky Linux"]},{"location":"recipes/basic_vasp_gcc_example/#7-an-example-script-to-compile-and-run-vasp","title":"7. An example script to compile and run VASP","text":"<p>The commands above can be combined into a single script as shown below. This example shows a script that can either be run from the command line or submitted to Slurm  as a batch job.</p> <pre><code>#!/bin/bash\n#SBATCH --time=12:00:00\n#SBATCH --partition=sched_mit_nse_r8\n#SBATCH -N 1\n#SBATCH --mem=0\n\ncd /nobackup1c/users/${USER}\ntnam=`mktemp -d VASP__TEMP_XXXX`\nmkdir -p ${tnam}\ncd ${tnam}\n\ntar -xzvf /nobackup1c/users/${USER}/vasp.6.4.2.tgz\ncd vasp.6.4.2\ncp arch/makefile.include.gnu_omp makefile.include\n\nmodule load  gcc/12.2.0-x86_64\nmodule load openmpi/4.1.4-pmi-cuda-ucx-x86_64\nmodule load netlib-lapack/3.10.1-x86_64\nmodule load netlib-scalapack/2.2.0-x86_64\nmodule load fftw/3.3.10-x86_64\nmodule load openblas/0.3.21-x86_64\n\nSCALAPACK_ROOT=`module -t show  netlib-scalapack 2&gt;&amp;1 | grep CMAKE_PREFIX_PATH | awk -F, '{print $2}'  | awk -F\\\" '{print $2}'`\nFFTW_ROOT=`pkgconf --variable=prefix fftw3`\nOPENBLAS_ROOT=$(dirname `pkgconf --variable=libdir openblas`)\n\nmake -j OPENBLAS_ROOT=$OPENBLAS_ROOT FFTW_ROOT=$FFTW_ROOT SCALAPACK_ROOT=$SCALAPACK_ROOT MODS=1 DEPS=1\n\nexport LD_LIBRARY_PATH=${OPENBLAS_ROOT}/lib:${FFTW_ROOT}/lib:${SCALAPACK_ROOT}/lib\n\n./bin/vasp_std\n</code></pre>","tags":["Engaging","Howto Recipes","MPI","cuda","cuda aware mpi","GPU","VASP","Rocky Linux"]},{"location":"recipes/gromacs/","title":"Installing and Using GROMACS","text":"<p>GROMACS is a free and open-source software suite for high-performance molecular dynamics and output analysis.</p> <p>You can learn about GROMACS here: https://www.gromacs.org/.</p>","tags":["Engaging","SuperCloud","MPI","GPU","GROMACS","Howto Recipes"]},{"location":"recipes/gromacs/#gromacs-on-engaging","title":"GROMACS on Engaging","text":"","tags":["Engaging","SuperCloud","MPI","GPU","GROMACS","Howto Recipes"]},{"location":"recipes/gromacs/#install-gromacs-with-mpi","title":"Install GROMACS with MPI","text":"<p>Select a version on the GROMACS website, then dowload and extract the tar ball. <pre><code>cd ~\nmkdir gromacs\ncd gromacs\nwget --no-check-certificate http://ftp.gromacs.org/pub/gromacs/gromacs-2019.6.tar.gz\ntar xvfz gromacs-2019.6.tar.gz\n</code></pre></p> <p>Load MPI and Cmake modules, <pre><code>module load engaging/openmpi/2.0.3 cmake/3.17.3\n</code></pre></p> <p>Create build and isntall directories, <pre><code>mkdir -p 2019.6/build\nmkdir 2019.6/install\ncd 2019.6/build\n</code></pre></p> <p>Use <code>cmake</code> to configure compiling options, <pre><code>cmake ~/gromacs/gromacs-2019.6 -DGMX_MPI=ON -DCMAKE_INSTALL_PREFIX=~/gromacs/2019.6/install\n</code></pre></p> <p>Compile, check and install, <pre><code>make\nmake check\nmake install\n</code></pre></p> <p>Set up usage enviroenment, <pre><code>source ~/gromacs/2019.6/install/bin/GMXRC\n</code></pre></p>","tags":["Engaging","SuperCloud","MPI","GPU","GROMACS","Howto Recipes"]},{"location":"recipes/gromacs/#gromacs-on-supercloud","title":"GROMACS on SuperCloud","text":"","tags":["Engaging","SuperCloud","MPI","GPU","GROMACS","Howto Recipes"]},{"location":"recipes/gromacs/#install-gromacs-with-mpi-and-cuda","title":"Install GROMACS with MPI and CUDA","text":"<p>Select a version on the GROMACS website, then dowload and extract the tar ball. <pre><code>cd ~\nmkdir gromacs\ncd gromacs\nwget http://ftp.gromacs.org/pub/gromacs/gromacs-2023.2.tar.gz\ntar xvfz gromacs-2023.2.tar.gz\n</code></pre></p> <p>Load CUDA, Anaconda and MPI modules, <pre><code>module load cuda/11.8 anaconda/2023a\nmodule load mpi/openmpi-4.1.5\n</code></pre></p> <p>Create build and isntall directories, <pre><code>mkdir -p 2023.2/build\nmkdir 2023.2/install\ncd 2023.2/build\n</code></pre></p> <p>Use <code>cmake</code> to configure compiling options, <pre><code>cmake ~/gromacs/gromacs-2023.2 -DGMX_MPI=ON -DGMX_GPU=CUDA -DCMAKE_INSTALL_PREFIX=~/gromacs/2023.2-gpu\n</code></pre></p> <p>Compile, check and install, <pre><code>make\nmake check\nmake install\n</code></pre></p> <p>Set up usage enviroenment before running GROMACS programs, <pre><code>source ~/gromacs/2023.2/install/bin/GMXRC\n</code></pre></p>","tags":["Engaging","SuperCloud","MPI","GPU","GROMACS","Howto Recipes"]},{"location":"recipes/gromacs/#run-gromacs","title":"Run GROMACS","text":"<p>Firstly, prepare for an input file. Refer to file formats. Here shows an example with an input file named <code>benchPEP-h.tpr</code> dowloaded from this page.</p> <p>Secondly, edit a batch job script, for example, named <code>job.sh</code>, requesting 2 node with 4 CPU cores and 2 GPUs per node. <pre><code>#!/bin/bash\n#SBATCH --nodes=2              # 2 nodes\n#SBATCH --ntasks-per-node=2    # 2 MPI tasks per node\n#SBATCH --cpus-per-task=2      # 2 CPU cores per task\n#SBATCH --gres=gpu:volta:2     # 2 GPUs per node\n#SBATCH --time=01:00:00        # 1 hour\n\n\n# Load required modules\nmodule load cuda/11.8 mpi/openmpi-4.1.5\n\n# Allow GROMACS to see GPUs\nexport CUDA_VISIBLE_DEVICES=0,1\n\n# Enable direct GPU to GPU communications\nexport GMX_ENABLE_DIRECT_GPU_COMM=true\n\n# Activate user install of GROMACS\nsource ~/gromacs/2023.2-gpu/bin/GMXRC\n\n# Check MPI, GPU and GROMACS\nmpirun hostname\nnvidia-smi\nwhich gmx_mpi\n\n# Run GROMACS\nmpirun gmx_mpi mdrun -s ~/gromacs/bench/benchPEP-h.tpr -ntomp ${SLURM_CPUS_PER_TASK} -pme gpu -update gpu -bonded gpu -npme 1\n</code></pre></p> <p>Finally, submit the job, <pre><code>sbatch job.sh\n</code></pre></p> <p>Refer to GROMACS user guide for more info.</p>","tags":["Engaging","SuperCloud","MPI","GPU","GROMACS","Howto Recipes"]},{"location":"recipes/h100_getting_started/","title":"Getting started on 8-way H100 nodes on Satori","text":"<p>This page provides information on how to run a first job on the IBM Watson AI Lab H100 GPU nodes on Satori. The page describes how to request an access to the Slurm partition associated  with the H100 nodes and how to run a first example pytorch script on the systems. </p> <p>A first set of H100 GPU systems has been added to Satori. These are for priority use by IBM Watson AI Lab research collaborators. They are also available for general opportunistic use when they are idle.</p> <p>Currently ( 2023-06-19 ) there are 4 H100 systems installed.  Each system has 8 H100 GPU cards, two Intel 8468 CPUs each with 48 physical cores and 1TiB of main memory.</p> <p>Below are some instructions for getting started with these systems. </p>","tags":["Satori","Howto Recipes","H100"]},{"location":"recipes/h100_getting_started/#access-to-the-nodes","title":"Access to the nodes","text":"<p>To access the nodes in the priority group you need your satori login id to be listed in the Webmoira  group https://groups.mit.edu/webmoira/list/sched_oliva.  Either Alex Andonian and Vincent Sitzmann are able to add accounts to the <code>sched_oliva</code> moira list.</p>","tags":["Satori","Howto Recipes","H100"]},{"location":"recipes/h100_getting_started/#interactive-access-through-slurm","title":"Interactive access through Slurm","text":"<p>To access an entire node through Slurm, the command below can be used from the satori login node</p> <pre><code>srun -p sched_oliva --gres=gpu:8 -N 1 --mem=0 -c 192 --time 1:00:00 --pty /bin/bash\n</code></pre> <p>this command will launch an interactive shell on one of the nodes (when a full node becomes available).  From this shell the NVidia status command  <pre><code>nvidia-smi\n</code></pre> should list 8 H100 GPUs as available. </p> <p>Single node, multi-gpu training examples (for example https://github.com/artidoro/qlora ) should run  on all 8 GPUs. </p> <p>To use a single GPU interactively the following command can be used <pre><code>srun -p sched_oliva --gres=gpu:1 --mem=128 -c 24 --time 1:00:00 --pty /bin/bash\n</code></pre></p> <p>this will request a single GPU. This request will allow other Slurm sessions to run on other GPUs  simultaneously with this session.</p>","tags":["Satori","Howto Recipes","H100"]},{"location":"recipes/h100_getting_started/#running-a-nightly-build-pytorch-example-with-a-freash-miniconda-and-pytorch","title":"Running a nightly build pytorch example with a freash miniconda and pytorch","text":"<p>A miniconda environment can be used to run the latest nightly build pytorch code on these  systems. To do this, first create a software install directory and install the needed pytorch software</p> <pre><code>mkdir -p /nobackup/users/${USER}/pytorch_h100_testing/conda_setup\n</code></pre> <p>and then switch your shell to that directory. <pre><code>cd /nobackup/users/${USER}/pytorch_h100_testing/conda_setup\n</code></pre></p> <p>now install miniconda and create an environment with the needed software <pre><code>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh \nchmod +x Miniconda3-latest-Linux-x86_64.sh\n./Miniconda3-latest-Linux-x86_64.sh -b -p minic\n. ./minic/bin/activate \nconda create -y -n pytorch_test python=3.10\nconda activate pytorch_test                          \nconda install -y -c conda-forge cupy\npip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121\n</code></pre></p> <p>Once the software is installed, the following script can be used to test the installation. <pre><code>cat &gt; test.py &lt;&lt;'EOF'\nimport torch\ndevice_id = torch.cuda.current_device()\ngpu_properties = torch.cuda.get_device_properties(device_id)\nprint(\"Found %d GPUs available. Using GPU %d (%s) of compute capability %d.%d with \"\n          \"%.1fGb total memory.\\n\" % \n          (torch.cuda.device_count(),\n          device_id,\n          gpu_properties.name,\n          gpu_properties.major,\n          gpu_properties.minor,\n          gpu_properties.total_memory / 1e9))\nEOF\n\npython test.py\n</code></pre></p> <p>To exit the Slurm srun session enter the command <pre><code>exit\n</code></pre></p>","tags":["Satori","Howto Recipes","H100"]},{"location":"recipes/h100_getting_started/#running-a-simple-batch-script-using-an-installed-miniconda-environment","title":"Running a simple batch script using an installed miniconda environment","text":"<p>To run a batch script on one of the H100 nodes in partition sched_oliva first paste the content in the  box below into a slurm script file called, for example, <code>test_script.slurm</code> ( change the RUNDIR setting to assign the  path to a directory where you have already installed a conda environment in a sub-directory called <code>minic</code> ).</p> <pre><code>#!/bin/bash\n#\n#SBATCH --gres=gpu:8\n#SBATCH --partition=sched_oliva\n#SBATCH --time=1:00:00\n#SBATCH --mem=0\n#\n\nnvidia-smi\n\nRUNDIR=/nobackup/users/${USER}/h100-testing/minic\ncd ${RUNDIR}\n\n. ./minic/bin/activate\n\nconda activate pytorch_test\n\ncat &gt; mytest.py &lt;&lt;'EOF'\nimport torch\ndevice_id = torch.cuda.current_device()\ngpu_properties = torch.cuda.get_device_properties(device_id)\nprint(\"Found %d GPUs available. Using GPU %d (%s) of compute capability %d.%d with \"\n          \"%.1fGb total memory.\\n\" %\n          (torch.cuda.device_count(),\n          device_id,\n          gpu_properties.name,\n          gpu_properties.major,\n          gpu_properties.minor,\n          gpu_properties.total_memory / 1e9))\nEOF\n\npython mytest.py\n</code></pre> <p>This script can then be submitted to Slurm to run in a background batch node using the command.</p> <pre><code>sbatch &lt; test_script.slurm\n</code></pre>","tags":["Satori","Howto Recipes","H100"]},{"location":"recipes/h100_getting_started/#getting-help","title":"Getting help","text":"<p>As always, please feel welcome to email orcd-help@mit.edu with questions, comments or suggestions. We would be happy to hear from you!</p>","tags":["Satori","Howto Recipes","H100"]},{"location":"recipes/mpi4py/","title":"Installing and Using MPI for Python","text":"<p>MPI for Python (<code>mpi4py</code>) provides Python bindings for the Message Passing Interface (MPI) standard, allowing Python applications to exploit multiple processors on workstations, clusters and supercomputers.</p> <p>You can learn about <code>mpi4py</code> here: https://mpi4py.readthedocs.io/en/stable/.</p>","tags":["OpenMind","MPI","Python","Howto Recipes"]},{"location":"recipes/mpi4py/#mpi4py-on-openmind","title":"Mpi4py on OpenMind","text":"","tags":["OpenMind","MPI","Python","Howto Recipes"]},{"location":"recipes/mpi4py/#install","title":"Install","text":"<p>If you use an Anaconda module, no installation is required.</p> <p>If you want to use Anaconda in your directory, refer to section 3 on this page to set it up, then intall <code>mpi4py</code>,  <pre><code>conda install -c conda-forge mpi4py\n</code></pre></p>","tags":["OpenMind","MPI","Python","Howto Recipes"]},{"location":"recipes/mpi4py/#run-mpi4py","title":"Run Mpi4py","text":"<p>Prepare your Python codes. Example 1: The following is a code for sending and receiving a dictionary. Save it in a file named <code>p2p-send-recv.py</code>. <pre><code>from mpi4py import MPI\n\ncomm = MPI.COMM_WORLD\nrank = comm.Get_rank()\n\nif rank == 0:\n    data = {'a': 7, 'b': 3.14}\n    comm.send(data, dest=1, tag=11)\n    print(rank,data)\nelif rank == 1:\n    data = comm.recv(source=0, tag=11)\n    print(rank,data)\n</code></pre></p> <p>Example 2: The following is a code for sending and receiving an array. Save it in a file named <code>p2p-array.py</code>. <pre><code>from mpi4py import MPI\nimport numpy\n\ncomm = MPI.COMM_WORLD\nrank = comm.Get_rank()\n\n# passing MPI datatypes explicitly\nif rank == 0:\n    data = numpy.arange(1000, dtype='i')\n    comm.Send([data, MPI.INT], dest=1, tag=77)\n    print(rank,data)\nelif rank == 1:\n    data = numpy.empty(1000, dtype='i')\n    comm.Recv([data, MPI.INT], source=0, tag=77)\n    print(rank,data)\n\n# automatic MPI datatype discovery\nif rank == 0:\n    data = numpy.arange(100, dtype=numpy.float64)\n    comm.Send(data, dest=1, tag=13)\n    print(rank,data)\nelif rank == 1:\n    data = numpy.empty(100, dtype=numpy.float64)\n    comm.Recv(data, source=0, tag=13)\n    print(rank,data)\n</code></pre></p> <p>Prepare a job script. The following is a job script for running <code>mpi4py</code> codes on 8 CPU cores of one node. Save it in a file named <code>p2p-job.sh</code>. <pre><code>#!/bin/bash -l\n#SBATCH -N 1\n#SBATCH -n 8\n\nmodule load openmpi/gcc/64/1.8.1\nmodule load openmind/anaconda/3-2022.05\n\nmpirun -np $SLURM_NTASKS python p2p-send-recv.py\nmpirun -np $SLURM_NTASKS python p2p-array.py\n</code></pre></p> <p>An Openmpi module is needed. If you use Anaconda in your directory, do not load the Anaconda module. </p> <p>Finally submit the job, <pre><code>sbatch p2p-job.sh\n</code></pre></p>","tags":["OpenMind","MPI","Python","Howto Recipes"]},{"location":"recipes/mujoco/","title":"Installing and Using MuJoCo","text":"<p>MuJoCo is a free and open source physics engine that aims to facilitate research and development in robotics, biomechanics, graphics and animation, and other areas where fast and accurate simulation is needed.</p> <p>You can learn about MuJoCo here: https://mujoco.org.</p> <p>Whether you are installing on Engaging or SuperCloud, you\u2019ll first have to install the MuJoCo binaries. This process is the same on all systems.</p>","tags":["Engaging","SuperCloud","Howto Recipes","MuJoCo"]},{"location":"recipes/mujoco/#install-the-mujoco-binaries","title":"Install the MuJoCo Binaries","text":"<p>First, install MuJoCo itself somewhere in your home directory. This is as simple as downloading the MuJoCo binaries, which can be found on their web page. For the release that you want, select the file that ends with \u201clinux-x86_64.tar.gz\u201d, for example for 2.3.0 select mujoco-2.3.0-linux-x86_64.tar.gz. Right click, and copy the link address. Then you can download on one of the login nodes with the \u201cwget\u201d command, and untar:</p> <pre><code>wget https://github.com/deepmind/mujoco/releases/download/2.3.0/mujoco-2.3.0-linux-x86_64.tar.gz\ntar -xzf mujoco-2.3.0-linux-x86_64.tar.gz\n</code></pre> <p>In order for mujoco-py to find the MuJoCo binaries, set the following paths:</p> <pre><code>export MUJOCO_PY_MUJOCO_PATH=$HOME/path/to/mujoco230/\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$MUJOCO_PY_MUJOCO_PATH/bin\n</code></pre>","tags":["Engaging","SuperCloud","Howto Recipes","MuJoCo"]},{"location":"recipes/mujoco/#mujoco-on-engaging","title":"MuJoCo on Engaging","text":"","tags":["Engaging","SuperCloud","Howto Recipes","MuJoCo"]},{"location":"recipes/mujoco/#install-mujoco-py","title":"Install Mujoco-Py","text":"<p>First, make sure the <code>MUJOCO_PY_MUJOCO_PATH</code> and <code>LD_LIBRARY_PATH</code> environment variables are set pointing to your mujoco installation. You can use the \u201cecho\u201d command to do this:</p> <pre><code>echo MUJOCO_PY_MUJOCO_PATH\necho LD_LIBRARY_PATH\n</code></pre> <p>If any of these are not set properly you can set them as described above (see here for MUJOCO_PY_MUJOCO_PATH, LD_LIBRARY_PATH.</p> <p>Next load either a Python or Anaconda module. In this example I loaded the latest anaconda3 module (run <code>module avail anaconda</code> to see the current list of available anaconda modules):</p> <pre><code>module load anaconda3/2022.10\n</code></pre> <p>From here on you can follow the standard instructions to install mujoco-py, using the <code>--user</code> flag where appropriate to install in your home directory, or install in an anaconda or virtual environment (do not use the <code>--user</code> flag if you want to install in a conda or virtual environment). Here I am installing in my home directory with <code>--user</code>:</p> <pre><code>pip install --user 'mujoco-py&lt;2.2,&gt;=2.1'\n</code></pre> <p>Start up python and import mujoco_py to complete the build process:</p> <pre><code>python\nimport mujoco_py\n</code></pre> <p>If you\u2019d like you can run the few example lines listed on install section of the mujoco-py github page to verify the install went through properly:</p> <pre><code>import mujoco_py\nimport os\nmj_path = mujoco_py.utils.discover_mujoco()\nxml_path = os.path.join(mj_path, 'model', 'humanoid.xml')\nmodel = mujoco_py.load_model_from_path(xml_path)\nsim = mujoco_py.MjSim(model)\nprint(sim.data.qpos)\nsim.step()\nprint(sim.data.qpos)\n</code></pre>","tags":["Engaging","SuperCloud","Howto Recipes","MuJoCo"]},{"location":"recipes/mujoco/#using-mujoco-in-a-job","title":"Using MuJoCo in a Job","text":"<p>To use MuJoCo you\u2019ll need to first load the same Python or Anaconda module you used to install mujoco-py. If you installed it into a conda environment or python virtual environment, load that environment as well. We recommend you do this in your job submission script rather than in your .bashrc or at the command line before you submit the job. This way you know your job is configured properly every time it runs. You can use the following test scripts to test your MuJoCo setup in a job environment, and as a starting point for your own job:</p> mujoco_test.py<pre><code>import mujoco_py\nimport os\n\nmj_path = mujoco_py.utils.discover_mujoco()\nxml_path = os.path.join(mj_path, 'model', 'humanoid.xml')\nmodel = mujoco_py.load_model_from_path(xml_path)\nsim = mujoco_py.MjSim(model)\n\nprint(sim.data.qpos)\nsim.step()\nprint(sim.data.qpos)\n</code></pre> submit_test.sh<pre><code>#!/bin/bash\n\n# Load the same python/anaconda module you used to install mujoco-py\nmodule load python/3.8.3\n\n# Run the script\npython mujoco_test.py\n</code></pre>","tags":["Engaging","SuperCloud","Howto Recipes","MuJoCo"]},{"location":"recipes/mujoco/#mujoco-on-supercloud","title":"MuJoCo on SuperCloud","text":"<p>MuJoCo, particularly mujoco-py, can be tricky to install on SuperCloud as it uses file locking during the install and whenever the package is loaded. File locking is disabled on the SuperCloud shared filesystem performance reasons, but is available on the local disk of each node. Therefore, one workaround is to install mujoco-py on the local disk of one of the login nodes and then copy the install to your home directory. To load the package, the install then needs to be copied to the local disk.</p> <p>We\u2019ve found the most success by doing this with a python virtual environment. By using a python virtual environment you can install any additional packages you need with mujoco-py, and they can be used along with packages in our anaconda module, unlike conda environments.</p> <p>If you haven't already, first follow the instructions above to install the MuJoCo binaries.</p>","tags":["Engaging","SuperCloud","Howto Recipes","MuJoCo"]},{"location":"recipes/mujoco/#create-the-virtual-environment","title":"Create the Virtual Environment","text":"<p>Next create the virtual environment on the local disk of the login node and install mujoco-py (install the version you would like to use):</p> <pre><code>module load anaconda/2023a\nmkdir /state/partition1/user/$USER\npython -m venv /state/partition1/user/$USER/mujoco_env\nsource /state/partition1/user/$USER/mujoco_env/bin/activate\npip install 'mujoco-py&lt;2.2,&gt;=2.1'\n</code></pre> <p>Now install any other packages you need to run your MuJoCo jobs. With virtual environments you won\u2019t see any of the packages you\u2019ve previously installed with <code>pip install --user</code> or what you may have installed in another environment. You should still be able to use any of the packages in the anaconda module you\u2019ve loaded, so no need to install any of those.</p> <pre><code>pip install pkgname1\npip install pkgname2\n</code></pre> <p>Since you are installing into virtual environment, do not use the <code>--user</code> flag.</p> <p>Once you\u2019ve installed the packages you need, start Python and import mujoco_py to finish the build:</p> <pre><code>python\nimport mujoco_py\n</code></pre> <p>Now that your environment is created, copy it to your home directory for permanent storage.</p> <pre><code>cp -r /state/partition1/user/$USER/mujoco_env $/software/mujoco/\n</code></pre>","tags":["Engaging","SuperCloud","Howto Recipes","MuJoCo"]},{"location":"recipes/mujoco/#running-a-job","title":"Running a Job","text":"<p>Now whenever you use mujoco-py the installation will need to be on the local disk of the node(s) where you are running. In your job script you can add a few lines of code that will check whether the environment exists on the local disk, and if not copy it. You can run these lines during an interactive job as well.</p> <pre><code># Set some useful environment variables\nexport MUJOCO_ENV_HOME=$HOME/software/mujoco/mujoco_env\nexport MUJOCO_ENV=/state/partition1/user/$USER/mujoco_env\n\n# Check if the environment exists on the local disk. If not copy it over from the home directory.\nif [ ! -d \"$MUJOCO_ENV\" ]; then\n    echo \"Copying $MUJOCO_ENV_HOME to $MUJOCO_ENV\"\n    mkdir -p /state/partition1/user/$USER\n    cp -r $MUJOCO_ENV_HOME $MUJOCO_ENV\nfi\n\n# Load an anaconda module, then activate your mujoco environment\nmodule load anaconda/2023a\nsource $MUJOCO_ENV/bin/activate\n</code></pre>","tags":["Engaging","SuperCloud","Howto Recipes","MuJoCo"]},{"location":"recipes/mujoco/#supercloud-test-scripts","title":"SuperCloud Test Scripts","text":"<p>The following are some test scripts you can use to check that your configuration worked.</p> mujoco_test.py<pre><code>import mujoco_py\nimport os\n\nmj_path = mujoco_py.utils.discover_mujoco()\nxml_path = os.path.join(mj_path, 'model', 'humanoid.xml')\nmodel = mujoco_py.load_model_from_path(xml_path)\nsim = mujoco_py.MjSim(model)\n\nprint(sim.data.qpos)\nsim.step()\nprint(sim.data.qpos)\n</code></pre> submit_test.sh<pre><code>#!/bin/bash\n\nexport MUJOCO_ENV_HOME=$HOME/software/mujoco/mujoco_env\nexport MUJOCO_ENV=/state/partition1/user/$USER/mujoco_env\n\nif [ ! -d \"$MUJOCO_ENV\" ]; then\n    echo \"Copying $MUJOCO_ENV_HOME to $MUJOCO_ENV\"\n    mkdir -p /state/partition1/user/$USER\n    cp -r $MUJOCO_ENV_HOME $MUJOCO_ENV\nfi\n\nmodule load anaconda/2022a\nsource $MUJOCO_ENV/bin/activate\n\npython mujoco_test.py\n</code></pre>","tags":["Engaging","SuperCloud","Howto Recipes","MuJoCo"]},{"location":"recipes/nvhpc-a100-with-cuda-and-mpi-example/","title":"Example of a minimal program using the nvhpc stack with CUDA aware MPI","text":"","tags":["Engaging","Satori","Howto Recipes","nvhpc","MPI","cuda","cuda aware mpi","GPU","Rocky Linux"]},{"location":"recipes/nvhpc-a100-with-cuda-and-mpi-example/#about-nvhpc","title":"About NVHPC","text":"<p>NVHPC is an integrated collection of software tools and libraries distributed by NVidia. An overview document describing nvhpc  can be found here. The aim of the nvhpc team is to provide up to date, preconfigured suites of compilers, libraries and tools that are  specifically optimized for NVidia GPU hardware. It supports single and multi-GPU execution.</p>","tags":["Engaging","Satori","Howto Recipes","nvhpc","MPI","cuda","cuda aware mpi","GPU","Rocky Linux"]},{"location":"recipes/nvhpc-a100-with-cuda-and-mpi-example/#basic-usage-example","title":"Basic Usage Example","text":"<p>This example shows steps for using NVHPC to run a simple test MPI program, written in C, that communicates between two GPUs. The detailed steps, that can be executed in an interactive Slurm session, are explained  below.  A complete Slurm job example is shown at the end.</p> <p>Prerequisites</p> <p>This example assumes you have access to a Slurm partition with GPU resources and are working with a Rocky Linux environment.</p>","tags":["Engaging","Satori","Howto Recipes","nvhpc","MPI","cuda","cuda aware mpi","GPU","Rocky Linux"]},{"location":"recipes/nvhpc-a100-with-cuda-and-mpi-example/#1-activate-the-relevant-nvhpc-module","title":"1. Activate the relevant NVHPC module","text":"<p>The NVHPC environment is installed as a module and can be made visible in a session using the command</p> <pre><code>module load nvhpc/2023_233/nvhpc/23.3\n</code></pre> <p>this will add a specific version of the nvhpc software (version 23.3 released in 2023) to a shell or batch script. The software added includes compilers for C, C++ and Fortran; base GPU optimized numerical libraries for linear algebra, Fourier transforms and others; GPU optimized communication libraries supporting MPI, SHMEM and NCCL APIs.</p> <p>An environment variable, <code>NVHPC_ROOT</code>, is also set. This can be used in scripts to reference the locations of libraries when needed.</p>","tags":["Engaging","Satori","Howto Recipes","nvhpc","MPI","cuda","cuda aware mpi","GPU","Rocky Linux"]},{"location":"recipes/nvhpc-a100-with-cuda-and-mpi-example/#2-set-paths-needed-for-compile-step","title":"2. Set paths needed for compile step","text":"<p>Here we use the module environment variable, <code>NVHPC_ROOT</code>, to set environment variables that have paths needed for compilation and linking of code.</p> <pre><code>culibdir=$NVHPC_ROOT/cuda/lib64\ncuincdir=$NVHPC_ROOT/cuda/include\n</code></pre>","tags":["Engaging","Satori","Howto Recipes","nvhpc","MPI","cuda","cuda aware mpi","GPU","Rocky Linux"]},{"location":"recipes/nvhpc-a100-with-cuda-and-mpi-example/#3-create-a-c-program-for-that-excutes-some-simple-multi-node-multi-gpu-test-code","title":"3. Create a C program for that excutes some simple multi-node, multi-GPU test code.","text":"<p>The next step is to create a file holding C code that uses MPI to send information between two GPUs  running in different processes. Paste the C code below into a file called <code>test.c</code>.</p> test.c<pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;mpi.h&gt;\n#include &lt;cuda_runtime.h&gt;\nint main(int argc, char *argv[])\n{\n  int myrank, mpi_nranks; \n  int LBUF=1000000;\n  float *sBuf_h, *rBuf_h;\n  float *sBuf_d, *rBuf_d;\n  int bSize;\n  int i;\n\n  MPI_Init(&amp;argc, &amp;argv);\n  MPI_Comm_rank(MPI_COMM_WORLD, &amp;myrank);                  // my MPI rank\n  MPI_Comm_size(MPI_COMM_WORLD, &amp;mpi_nranks);\n\n  if ( mpi_nranks != 2 ) { printf(\"Program requires exactly 2 ranks\\n\");exit(-1); }\n\n  int deviceCount;\n  cudaGetDeviceCount(&amp;deviceCount);               // How many GPUs?\n  printf(\"Number of GPUs found = %d\\n\",deviceCount);\n  int device_id = myrank % deviceCount;\n  cudaSetDevice(device_id);                       // Map MPI-process to a GPU\n  printf(\"Assigned GPU %d to MPI rank %d of %d.\\n\",device_id, myrank, mpi_nranks);\n\n  // Allocate buffers on each host and device\n  bSize = sizeof(float)*LBUF;\n  sBuf_h = malloc(bSize);\n  rBuf_h = malloc(bSize);\n  for (i=0;i&lt;LBUF;++i){\n    sBuf_h[i]=(float)myrank;\n    rBuf_h[i]=-1.;\n  }\n  if ( myrank == 0 ) {\n   printf(\"rBuf_h[0] = %f\\n\",rBuf_h[0]);\n  }\n\n  cudaMalloc((void **)&amp;sBuf_d,bSize);\n  cudaMalloc((void **)&amp;rBuf_d,bSize);\n\n  cudaMemcpy(sBuf_d,sBuf_h,bSize,cudaMemcpyHostToDevice);\n\n  if ( myrank == 0 ) {\n   MPI_Recv(rBuf_d,LBUF,MPI_REAL,1,0,MPI_COMM_WORLD,MPI_STATUS_IGNORE);\n  } \n  else if ( myrank == 1 ) {\n   MPI_Send(sBuf_d,LBUF,MPI_REAL,0,0,MPI_COMM_WORLD);\n  }\n  else\n  {\n   printf(\"Unexpected myrank value %d\\n\",myrank);\n   exit(-1);\n  }\n\n  cudaMemcpy(rBuf_h,rBuf_d,bSize,cudaMemcpyDeviceToHost);\n  if ( myrank == 0 ) {\n   printf(\"rBuf_h[0] = %f\\n\",rBuf_h[0]);\n  }\n\n  MPI_Barrier(MPI_COMM_WORLD);\n  MPI_Finalize();\n}\n</code></pre>","tags":["Engaging","Satori","Howto Recipes","nvhpc","MPI","cuda","cuda aware mpi","GPU","Rocky Linux"]},{"location":"recipes/nvhpc-a100-with-cuda-and-mpi-example/#4-compile-program","title":"4. Compile program","text":"<p>Here we use nvhpc MPI wrapper to compile. The two environment variables we set earlier (<code>cuincdir</code> and <code>culibdir</code>) are used to let the compile step know where to find the relevant CUDA header and library files. The CUDA runtime library (<code>cudart</code>) is added as a location for finding CUDA functions the code utilizes.</p> <pre><code>mpicc test.c -I${cuincdir} -L${culibdir} -lcudart\n</code></pre>","tags":["Engaging","Satori","Howto Recipes","nvhpc","MPI","cuda","cuda aware mpi","GPU","Rocky Linux"]},{"location":"recipes/nvhpc-a100-with-cuda-and-mpi-example/#5-execute-program","title":"5. Execute program","text":"<p>Once code has been compiled the <code>mpiexec</code> command that is part of the <code>nvhpc</code> module can be used to run the test program. The <code>nvhpc</code> module defaults to using its builtin version of OpneMPI. The OpenMPI option <code>btl_openib_warn_no_device_params_found</code> is passed into the OpenMPI runtime library. This option supresses a warning that OpenMPI can generate when it encounters a network device card that is not present in a built-in list that OpenMPI has historically included.</p> <pre><code>mpiexec --mca btl_openib_warn_no_device_params_found 0 -n 2 ./a.out \n</code></pre> <p>Running this program using the command above should produce the following output.</p> <pre><code>Number of GPUs found = 1\nNumber of GPUs found = 1\nAssigned GPU 0 to MPI rank 0 of 2.\nrBuf_h[0] = -1.000000\nAssigned GPU 0 to MPI rank 1 of 2.\nrBuf_h[0] = 1.000000\n</code></pre>","tags":["Engaging","Satori","Howto Recipes","nvhpc","MPI","cuda","cuda aware mpi","GPU","Rocky Linux"]},{"location":"recipes/nvhpc-a100-with-cuda-and-mpi-example/#example-of-slurm-job-file-for-excuting-this-example","title":"Example of Slurm job file for excuting this example","text":"<p>The job script file below will run all the steps described above. It can  be submitted to Slurm using the command <code>sbatch</code> followed by the filename holding the job script.</p> <pre><code>#!/bin/bash\n#SBATCH -p sched_system_all\n#SBATCH --constraint=rocky8\n#SBATCH -N 2\n#SBATCH -n 2\n#SBATCH --gres=gpu:2\n#SBATCH --time=00:02:00\n#\n# Basic slurm job that tests GPU aware MPI in the NVHPC tool stack.\n#\n#\n#   To submit through Slurm use:\n#\n#   $ sbatch test_cuda_and_mpi.sbatch\n#  \n#   in terminal.\n\n# Write a little log info\necho \"## Start time \\\"\"`date`\"\\\"\"\necho \"## Slurm job running on nodes \\\"${SLURM_JOB_NODELIST}\\\"\"\necho \"## Slurm submit directory \\\"${SLURM_SUBMIT_DIR}\\\"\"\necho \"## Slurm submit host \\\"${SLURM_SUBMIT_HOST}\\\"\"\necho \" \"\n\n\nmodule load nvhpc/2023_233/nvhpc/23.3\nculibdir=$NVHPC_ROOT/cuda/lib64\ncuincdir=$NVHPC_ROOT/cuda/include\n\ncat &gt; test.c &lt;&lt;'EOFA'\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;mpi.h&gt;\n#include &lt;cuda_runtime.h&gt;\nint main(int argc, char *argv[])\n{\n  int myrank, mpi_nranks; \n  int LBUF=1000000;\n  float *sBuf_h, *rBuf_h;\n  float *sBuf_d, *rBuf_d;\n  int bSize;\n  int i;\n\n  MPI_Init(&amp;argc, &amp;argv);\n  MPI_Comm_rank(MPI_COMM_WORLD, &amp;myrank);                  // my MPI rank\n  MPI_Comm_size(MPI_COMM_WORLD, &amp;mpi_nranks);\n\n  if ( mpi_nranks != 2 ) { printf(\"Program requires exactly 2 ranks\\n\");exit(-1); }\n\n  int deviceCount;\n  cudaGetDeviceCount(&amp;deviceCount);               // How many GPUs?\n  printf(\"Number of GPUs found = %d\\n\",deviceCount);\n  int device_id = myrank % deviceCount;\n  cudaSetDevice(device_id);                       // Map MPI-process to a GPU\n  printf(\"Assigned GPU %d to MPI rank %d of %d.\\n\",device_id, myrank, mpi_nranks);\n\n  // Allocate buffers on each host and device\n  bSize = sizeof(float)*LBUF;\n  sBuf_h = malloc(bSize);\n  rBuf_h = malloc(bSize);\n  for (i=0;i&lt;LBUF;++i){\n    sBuf_h[i]=(float)myrank;\n    rBuf_h[i]=-1.;\n  }\n  if ( myrank == 0 ) {\n   printf(\"rBuf_h[0] = %f\\n\",rBuf_h[0]);\n  }\n\n  cudaMalloc((void **)&amp;sBuf_d,bSize);\n  cudaMalloc((void **)&amp;rBuf_d,bSize);\n\n  cudaMemcpy(sBuf_d,sBuf_h,bSize,cudaMemcpyHostToDevice);\n\n  if ( myrank == 0 ) {\n   MPI_Recv(rBuf_d,LBUF,MPI_REAL,1,0,MPI_COMM_WORLD,MPI_STATUS_IGNORE);\n  } \n  else if ( myrank == 1 ) {\n   MPI_Send(sBuf_d,LBUF,MPI_REAL,0,0,MPI_COMM_WORLD);\n  }\n  else\n  {\n   printf(\"Unexpected myrank value %d\\n\",myrank);\n   exit(-1);\n  }\n\n  cudaMemcpy(rBuf_h,rBuf_d,bSize,cudaMemcpyDeviceToHost);\n  if ( myrank == 0 ) {\n   printf(\"rBuf_h[0] = %f\\n\",rBuf_h[0]);\n  }\n\n  MPI_Barrier(MPI_COMM_WORLD);\n  MPI_Finalize();\n}\nEOFA\n\nmpicc test.c -I${cuincdir} -L${culibdir} -lcudart\n\nmpiexec --mca btl_openib_warn_no_device_params_found 0 -n 2 ./a.out \n</code></pre>","tags":["Engaging","Satori","Howto Recipes","nvhpc","MPI","cuda","cuda aware mpi","GPU","Rocky Linux"]},{"location":"tags/","title":"Tags","text":"<p>Following is a list of relevant tags:</p>"},{"location":"tags/#engaging","title":"Engaging","text":"<ul> <li>ORCD Systems</li> <li>Example of a build of the VASP software.</li> <li>GROMACS</li> <li>MuJoCo</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#gpu","title":"GPU","text":"<ul> <li>Example of a build of the VASP software.</li> <li>GROMACS</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#gromacs","title":"GROMACS","text":"<ul> <li>GROMACS</li> </ul>"},{"location":"tags/#h100","title":"H100","text":"<ul> <li>Getting started on 8-way H100 nodes on Satori</li> </ul>"},{"location":"tags/#howto-recipes","title":"Howto Recipes","text":"<ul> <li>Example of a build of the VASP software.</li> <li>GROMACS</li> <li>Getting started on 8-way H100 nodes on Satori</li> <li>MPI for Python</li> <li>MuJoCo</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#mpi","title":"MPI","text":"<ul> <li>Example of a build of the VASP software.</li> <li>GROMACS</li> <li>MPI for Python</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#mujoco","title":"MuJoCo","text":"<ul> <li>MuJoCo</li> </ul>"},{"location":"tags/#openmind","title":"OpenMind","text":"<ul> <li>MPI for Python</li> </ul>"},{"location":"tags/#python","title":"Python","text":"<ul> <li>MPI for Python</li> </ul>"},{"location":"tags/#rocky-linux","title":"Rocky Linux","text":"<ul> <li>Example of a build of the VASP software.</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#satori","title":"Satori","text":"<ul> <li>ORCD Systems</li> <li>Getting started on 8-way H100 nodes on Satori</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#supercloud","title":"SuperCloud","text":"<ul> <li>ORCD Systems</li> <li>GROMACS</li> <li>MuJoCo</li> </ul>"},{"location":"tags/#vasp","title":"VASP","text":"<ul> <li>Example of a build of the VASP software.</li> </ul>"},{"location":"tags/#cuda","title":"cuda","text":"<ul> <li>Example of a build of the VASP software.</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#cuda-aware-mpi","title":"cuda aware mpi","text":"<ul> <li>Example of a build of the VASP software.</li> <li>NVHPC with CUDA aware MPI</li> </ul>"},{"location":"tags/#nvhpc","title":"nvhpc","text":"<ul> <li>NVHPC with CUDA aware MPI</li> </ul>"}]}